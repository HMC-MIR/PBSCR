{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = 9\n",
    "\n",
    "# Extract and open datasets\n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(f\"{ways}_way_dataset.zip\", 'r') as f:\n",
    "    f.extractall()\n",
    "\n",
    "with open(f\"{ways}_way_dataset.pkl\", \"rb\") as f:\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test, m_train, m_valid, m_test = pickle.load(f)\n",
    "\n",
    "composers = np.unique(y_train)\n",
    "y_train = np.stack(y_train)\n",
    "y_test = np.stack(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90,)\n",
      "(90, 64, 62)\n"
     ]
    }
   ],
   "source": [
    "def sample_data(N=10):\n",
    "    composer_pieces = {composer:x_train[np.argwhere(y_train == composers[0]).flatten()] for composer in composers}\n",
    "    composer_pieces = {k:v[np.random.choice(np.arange(len(v)), size=(N,), replace=False)] for k, v in composer_pieces.items()}\n",
    "\n",
    "    y_few = []\n",
    "    x_few = []\n",
    "\n",
    "    for composer, pieces in composer_pieces.items():\n",
    "        for piece in pieces:\n",
    "            y_few.append(composer)\n",
    "            x_few.append(piece)\n",
    "\n",
    "    y_few = np.array(y_few)\n",
    "    x_few = np.stack(x_few)\n",
    "\n",
    "    return x_few, y_few\n",
    "\n",
    "x_few, y_few = sample_data()\n",
    "\n",
    "print(y_few.shape)\n",
    "print(x_few.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Helper func\n",
    "def expand_repeat(arr, repeats, axis=0):\n",
    "    return np.repeat(np.expand_dims(arr, axis=axis), repeats, axis=axis)\n",
    "\n",
    "def fit_and_predict(x_few, y_few, x_test, extractor): # Function to take x_few and y_few and make guesses about all the x_test samples\n",
    "    y_pred = None\n",
    "\n",
    "    few_features = extractor(x_few) # L x d (where L is N*#composers)\n",
    "    test_features = extractor(x_test)# M x d\n",
    "\n",
    "    # Want to end with M x L vector\n",
    "\n",
    "    euclideans = np.sqrt(np.sum(np.square(expand_repeat(few_features, len(x_test), 0) - expand_repeat(test_features, N*ways, 1)), axis=-1))\n",
    "\n",
    "    avg_euclideans = np.zeros((len(x_test), ways))\n",
    "\n",
    "    for i, composer in enumerate(composers):\n",
    "        composer_points = np.argwhere(y_few == composer).flatten()\n",
    "\n",
    "        avg_euclideans[:, i] = np.mean(euclideans[:, composer_points], axis=-1)\n",
    "\n",
    "    ranks = np.argsort(avg_euclideans, axis=-1)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_acc(y_true, y_pred, x):\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "    # ranked = torch.argsort(y_pred, axis=-1)\n",
    "    top_x = y_pred[..., :x]\n",
    "    # print(ranked.shape)\n",
    "    return (top_x == torch.repeat_interleave(y_true.unsqueeze(-1), x, axis=-1)).float().sum(-1).mean().item()\n",
    "\n",
    "def mean_recip_rank(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "    # ranked = torch.argsort(y_pred, axis=-1)\n",
    "    \n",
    "    # print(ranked.shape, torch.repeat_interleave(y_true.unsqueeze(-1), y_true.shape[-1], axis=-1).shape)\n",
    "\n",
    "    # starts with worst at 0 but we want best at 1 so\n",
    "    true_ranks = (y_pred == torch.repeat_interleave(y_true.unsqueeze(-1), y_pred.shape[-1], axis=-1)).float().argmax(-1) + 1\n",
    "\n",
    "    return (1/true_ranks).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 30\n",
    "\n",
    "\n",
    "def random_extractor(x): # function to get extracted features from data\n",
    "    d = 5\n",
    "    return np.random.normal(size=(len(x), d))\n",
    "\n",
    "\n",
    "models = {\"Random\":random_extractor}\n",
    "Ns = [1, 10, 100]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for N in Ns:\n",
    "    results[N] = {}\n",
    "\n",
    "    for model_name, extractor in models.items():\n",
    "\n",
    "        top1s = []\n",
    "        top5s = []\n",
    "        mrrs = []\n",
    "\n",
    "        for _ in range(T):\n",
    "            x_few, y_few = sample_data(N=N)\n",
    "\n",
    "            y_pred = fit_and_predict(x_few, y_few, x_test, extractor)\n",
    "            y_true = np.array([list(composers).index(i) for i in y_test])\n",
    "\n",
    "            top1 = top_x_acc(y_true, y_pred, 1)\n",
    "            top5 = top_x_acc(y_true, y_pred, 5)\n",
    "            mrr = mean_recip_rank(y_true, y_pred)\n",
    "\n",
    "            top1s.append(top1)\n",
    "            top5s.append(top5)\n",
    "            mrrs.append(mrr)\n",
    "\n",
    "        results[N][model_name] = {\"top1\":np.mean(top1s), \"top5\":np.mean(top5s), \"mrr\":np.mean(mrrs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'Random': {'top1': 0.1113998552163442, 'top5': 0.5545449495315552, 'mrr': 0.31415307422478994}}, 10: {'Random': {'top1': 0.11055583258469899, 'top5': 0.5546393533547719, 'mrr': 0.3136714696884155}}, 100: {'Random': {'top1': 0.11144427756468454, 'top5': 0.5534010708332062, 'mrr': 0.3141970207293828}}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EWLLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

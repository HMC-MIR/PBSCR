{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"\"  # your username\n",
    "\n",
    "with open(f\"/home/{username}/ttmp/PBSCR/baselines/9_class_dataset.pkl\", \"rb\") as f:\n",
    "    (\n",
    "        x_train9,\n",
    "        y_train9,\n",
    "        x_valid9,\n",
    "        y_valid9,\n",
    "        x_test9,\n",
    "        y_test9,\n",
    "        m_train9,\n",
    "        m_valid9,\n",
    "        m_test9,\n",
    "    ) = pickle.load(f)\n",
    "\n",
    "with open(f\"/home/{username}/ttmp/PBSCR/baselines/100_class_dataset.pkl\", \"rb\") as f:\n",
    "    (\n",
    "        x_train100,\n",
    "        y_train100,\n",
    "        x_valid100,\n",
    "        y_valid100,\n",
    "        x_test100,\n",
    "        y_test100,\n",
    "        m_train100,\n",
    "        m_valid100,\n",
    "        m_test100,\n",
    "    ) = pickle.load(f)\n",
    "\n",
    "composers9 = np.unique(y_train9)\n",
    "composers100 = np.unique(y_train100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(y_train, composers, N=10):\n",
    "    composer_pieces = {\n",
    "        composer: np.argwhere(y_train == composer).flatten() for composer in composers\n",
    "    }\n",
    "    indices = np.concatenate(\n",
    "        [\n",
    "            np.random.choice(piece_indices, size=(N,), replace=False)\n",
    "            for piece_indices in composer_pieces.values()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper funcs\n",
    "def expand_repeat(arr, repeats, axis=0):\n",
    "    return np.repeat(np.expand_dims(arr, axis=axis), repeats, axis=axis)\n",
    "\n",
    "\n",
    "def fit_and_predict(\n",
    "    train_features, test_features, indices, y_train, composers, k=3\n",
    "):  # Function to take x_few and y_few and make guesses about all the x_test samples\n",
    "    avg_euclideans = np.zeros((len(test_features), len(composers)))\n",
    "    few_features = train_features[indices]  # L x d (where L is N*#composers)\n",
    "    batch_size = 128\n",
    "\n",
    "    for i, composer in enumerate(composers):\n",
    "        composer_points = np.argwhere(y_train[indices] == composer).flatten()\n",
    "        euclideans = np.zeros((len(test_features), len(composer_points)))\n",
    "\n",
    "        for batch in range(\n",
    "            0, int(batch_size * np.ceil(len(test_features) / batch_size)), batch_size\n",
    "        ):\n",
    "            test_batch = test_features[batch : batch + batch_size]\n",
    "            euclideans[batch : batch + batch_size] = np.sqrt(\n",
    "                np.sum(\n",
    "                    np.square(\n",
    "                        expand_repeat(few_features[composer_points], len(test_batch), 0)\n",
    "                        - expand_repeat(test_batch, len(composer_points), 1)\n",
    "                    ),\n",
    "                    axis=-1,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        avg_euclideans[:, i] = np.mean(np.sort(euclideans, axis=-1)[..., :k], axis=-1)\n",
    "\n",
    "    ranks = np.argsort(avg_euclideans, axis=-1)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_acc(y_true, y_pred, x):\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "\n",
    "    top_x = y_pred[..., :x]\n",
    "    return (\n",
    "        (top_x == torch.repeat_interleave(y_true.unsqueeze(-1), x, axis=-1))\n",
    "        .float()\n",
    "        .sum(-1)\n",
    "        .mean()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "\n",
    "def mean_recip_rank(y_true, y_pred):\n",
    "    y_true = torch.Tensor(y_true)\n",
    "    y_pred = torch.Tensor(y_pred)\n",
    "\n",
    "    # starts with worst at 0 but we want best at 1 so\n",
    "    true_ranks = (\n",
    "        y_pred\n",
    "        == torch.repeat_interleave(y_true.unsqueeze(-1), y_pred.shape[-1], axis=-1)\n",
    "    ).float().argmax(-1) + 1\n",
    "\n",
    "    return (1 / true_ranks).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Way dataset:\n",
      "\n",
      "N: 1\n",
      "\n",
      "\n",
      "Model: gpt2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faa15fef844deca6bf0a258ebcabb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top1': (0.15403409401575724, 0.021760802331783652), 'top5': (0.6186351299285888, 0.03215427742307966), 'top10': None, 'mrr': (0.3595596253871918, 0.020848075841654427)}\n",
      "\n",
      "Model: roberta\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b801172dae416797b6a84616d1e1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top1': (0.12643678163488706, 0.008172099175515249), 'top5': (0.5828918894131978, 0.014910360959397287), 'top10': None, 'mrr': (0.33158112366994225, 0.008192236926892289)}\n",
      "\n",
      "Model: random\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94ec75544a54cd38dad50644c589803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'top1': (0.11172191674510638, 0.004455461120023086), 'top5': (0.5563496053218842, 0.005252118659607039), 'top10': None, 'mrr': (0.31513874530792235, 0.0034284402313440932)}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "models = [\"gpt2\", \"roberta\", \"random\"]\n",
    "T = 30\n",
    "Ns = [1]  # , 10, 100]\n",
    "datasets = {\n",
    "    \"9\": (y_train9, y_test9, composers9),\n",
    "    # \"100\":(y_train100, y_test100, composers100)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for classs, (y_train, y_test, composers) in datasets.items():\n",
    "    print(f\"{classs} class dataset:\")\n",
    "\n",
    "    results[classs] = {}\n",
    "\n",
    "    for N in Ns:\n",
    "        results[classs][N] = {}\n",
    "        print()\n",
    "        print(f\"N: {N}\")\n",
    "        print()\n",
    "\n",
    "        for model in models:\n",
    "            train_features, test_features = (\n",
    "                np.load(f\"fewshot_vecs/{model}_train{classs}.npy\"),\n",
    "                np.load(f\"fewshot_vecs/{model}_test{classs}.npy\"),\n",
    "            )\n",
    "\n",
    "            print()\n",
    "            print(f\"Model: {model}\")\n",
    "\n",
    "            top1s = []\n",
    "            top5s = []\n",
    "            mrrs = []\n",
    "            top10s = []\n",
    "\n",
    "            for _ in tqdm(range(T)):\n",
    "                indices = get_indices(y_train, composers, N=N)\n",
    "\n",
    "                y_pred = fit_and_predict(\n",
    "                    train_features, test_features, indices, y_train, composers, k=3\n",
    "                )\n",
    "                y_true = np.array([list(composers).index(i) for i in y_test])\n",
    "\n",
    "                top1s.append(top_x_acc(y_true, y_pred, 1))\n",
    "                top5s.append(top_x_acc(y_true, y_pred, 5))\n",
    "                mrrs.append(mean_recip_rank(y_true, y_pred))\n",
    "\n",
    "                if classs == \"100\":\n",
    "                    top10s.append(top_x_acc(y_true, y_pred, 10))\n",
    "\n",
    "            results[classs][N][model] = {\n",
    "                \"top1\": (np.mean(top1s), np.std(top1s)),\n",
    "                \"top5\": (np.mean(top5s), np.std(top5s)),\n",
    "                \"top10\": (np.mean(top10s), np.std(top10s)) if top10s else None,\n",
    "                \"mrr\": (np.mean(mrrs), np.std(mrrs)),\n",
    "            }\n",
    "            print(results[classs][N][model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"r\") as f:\n",
    "    results = json.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

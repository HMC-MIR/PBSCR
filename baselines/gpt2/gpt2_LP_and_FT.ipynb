{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import time\n",
    "import evaluate\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.normalizers import Sequence, Lowercase, NFD, StripAccents\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    GPT2Config,\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from transformers import get_scheduler, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_acc(y_true, y_pred, x):\n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "    ranked = torch.argsort(y_pred, axis=-1)\n",
    "    top_x = ranked[..., -x:]\n",
    "    return (\n",
    "        (top_x == torch.repeat_interleave(y_true.unsqueeze(-1), x, axis=-1))\n",
    "        .float()\n",
    "        .sum(-1)\n",
    "        .mean()\n",
    "        .item()\n",
    "    )\n",
    "\n",
    "\n",
    "def mean_recip_rank(y_true, y_pred):\n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "    ranked = torch.argsort(y_pred, axis=-1)\n",
    "    true_ranks = y_pred.shape[-1] - (\n",
    "        ranked\n",
    "        == torch.repeat_interleave(y_true.unsqueeze(-1), y_pred.shape[-1], axis=-1)\n",
    "    ).float().argmax(-1)\n",
    "\n",
    "    return (1 / true_ranks).mean().item()\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    top_one = top_x_acc(labels, predictions, 1)\n",
    "    top_five = top_x_acc(labels, predictions, 5)\n",
    "    top_ten = 0\n",
    "    if predictions.shape[-1] >= 10:\n",
    "        top_ten = top_x_acc(labels, predictions, 10)\n",
    "    mrr = mean_recip_rank(labels, predictions)\n",
    "\n",
    "    metrics = {\"top_one\": top_one, \"top_five\": top_five, \"mrr\": mrr, \"top_ten\": top_ten}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_staff_overlaps(bscores):\n",
    "    \"\"\"\n",
    "    Takes in either one binary score or a batch of them and merges the left and right hands\n",
    "    \"\"\"\n",
    "\n",
    "    # Lower middle c is index 23\n",
    "    # Upper middle c is index 33\n",
    "    lower = 23\n",
    "    upper = 33\n",
    "    middle = (lower + upper) // 2\n",
    "\n",
    "    # Total notes is 52\n",
    "    total = 52\n",
    "\n",
    "    # Pad out upper hand and lower hand and combine them\n",
    "    padded_lower = np.concatenate(\n",
    "        [bscores[..., :middle], np.zeros((*bscores.shape[:-1], total - middle))],\n",
    "        axis=-1,\n",
    "    )\n",
    "    padded_upper = np.concatenate(\n",
    "        [\n",
    "            np.zeros((*bscores.shape[:-1], middle - bscores.shape[-1] + total)),\n",
    "            bscores[..., middle:],\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    # Logical or\n",
    "    merged = padded_lower + padded_upper - padded_lower * padded_upper\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Continuous line of 256 unicode characters\n",
    "start = 10060  # 931\n",
    "dense_characters = [\n",
    "    chr(i).encode(\"utf-8\").decode(\"utf-8\") for i in range(start, start + 512)\n",
    "]\n",
    "\n",
    "\n",
    "# This code divides the fragment into blocks (and discards any remaining info at the very edges)\n",
    "# Then it uses einsum with a filter of powers of 2 to convert from binary to an integer.  Then converts integers into\n",
    "# unicode characters\n",
    "\n",
    "\n",
    "def dense_encoder(fragment, block_size=[1, 1]):\n",
    "    fragment = merge_staff_overlaps(fragment)\n",
    "    # Rewrote this to be much faster but looks complicated\n",
    "    # This filter has powers of 2 which is how the binary is turned to ints\n",
    "    filter_ = np.power(2, np.arange(np.prod(block_size))).reshape(block_size)\n",
    "\n",
    "    # The fragment is split into blocks here\n",
    "    xblocks = np.stack(\n",
    "        np.split(\n",
    "            fragment[:, : (fragment.shape[1] // block_size[1]) * block_size[1]],\n",
    "            fragment.shape[1] // block_size[1],\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "    xyblocks = np.stack(\n",
    "        np.split(\n",
    "            xblocks[:, : (xblocks.shape[1] // block_size[0]) * block_size[0]],\n",
    "            xblocks.shape[1] // block_size[0],\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The blocks are multiplied so they are ints\n",
    "    numbers = np.einsum(\"ijkl,kl->ij\", xyblocks, filter_)\n",
    "\n",
    "    # The ints are turned into corresponding characters\n",
    "    characters = (numbers + start).astype(np.int32).view(\"U1\")\n",
    "    return \" \".join([\"\".join(t) for t in characters])\n",
    "\n",
    "\n",
    "def data_preparation(labeled_data):\n",
    "    train_X, train_y, val_X, val_y, test_X, test_y, train_m, valid_m, test_m = (\n",
    "        pd.read_pickle(labeled_data)\n",
    "    )\n",
    "\n",
    "    train_df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": [dense_encoder(piece, block_size=[1, 8]) for piece in train_X],\n",
    "            \"label\": train_y,\n",
    "        }\n",
    "    )\n",
    "    val_df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": [dense_encoder(piece, block_size=[1, 8]) for piece in val_X],\n",
    "            \"label\": val_y,\n",
    "        }\n",
    "    )\n",
    "    test_df = pd.DataFrame(\n",
    "        {\n",
    "            \"text\": [dense_encoder(piece, block_size=[1, 8]) for piece in test_X],\n",
    "            \"label\": test_y,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "\n",
    "def label2id_function(examples, label2id):\n",
    "    return {\"label\": [label2id[label] for label in examples[\"label\"]]}\n",
    "\n",
    "\n",
    "def tokenizer_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep and load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "username = \"\"  # your username\n",
    "\n",
    "gpt2_dir = Path(f\"/home/{username}/ttmp/PBSCR/gpt2\")\n",
    "seed = 42\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(gpt2_dir / \"tokenizer\")\n",
    "tokenizer.pad_token = \"<pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb05ee3c376c49d38d0fb60acc013c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd1edf9766243b9a61e82351c070e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba132d296c64128a9a30ae5ea4770f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b8196bdd5e4276aff821c1a680b3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552c98d848ec4467afa57420dcd5a0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d670ad9816446da2afc7c38155e173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeled_data = f\"/home/{username}/ttmp/PBSCR/baselines/9_way_dataset.pkl\"\n",
    "# labeled_data = f\"/home/{username}/ttmp/PBSCR/baselines/100_way_dataset.pkl\"\n",
    "train_df, val_df, test_df = data_preparation(labeled_data)\n",
    "train_ds = Dataset.from_dict(train_df)\n",
    "val_ds = Dataset.from_dict(val_df)\n",
    "test_ds = Dataset.from_dict(test_df)\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(set(train_df[\"label\"]))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n",
    "train_ds = train_ds.map(\n",
    "    label2id_function, batched=True, fn_kwargs={\"label2id\": label2id}\n",
    ")\n",
    "val_ds = val_ds.map(label2id_function, batched=True, fn_kwargs={\"label2id\": label2id})\n",
    "val_ds = val_ds.map(\n",
    "    tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n",
    "test_ds = test_ds.map(\n",
    "    tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer}\n",
    ")\n",
    "test_ds = test_ds.map(label2id_function, batched=True, fn_kwargs={\"label2id\": label2id})\n",
    "\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, padding=\"longest\", max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(gpt2_dir / \"pretrained_model\")\n",
    "config.num_labels = len(label2id)\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "model = AutoModelForSequenceClassification.from_config(config=config)\n",
    "\n",
    "# Freeze all layers except the classifier\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "model.score.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=gpt2_dir / \"classifier_9_no_pretrained\",\n",
    "    # output_dir=gpt2_dir/\"classifier_100_no_pretrained\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Probe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(gpt2_dir / \"pretrained_model\")\n",
    "config.num_labels = len(label2id)\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    gpt2_dir / \"pretrained_model\", config=config\n",
    ")\n",
    "\n",
    "# Freeze all layers except the classifier\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "model.score.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # output_dir=gpt2_dir/\"classifier_9_pretrained\",\n",
    "    # output_dir=gpt2_dir/\"classifier_100_pretrained\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr in [5e-5 / 100, 5e-5 / 300, 5e-5 / 1000]:\n",
    "    # os.makedirs(gpt2_dir/f\"LPFT_9_{lr}\", exist_ok=True)\n",
    "    os.makedirs(gpt2_dir / f\"LPFT_100_{lr}\", exist_ok=True)\n",
    "\n",
    "    # config = AutoConfig.from_pretrained(gpt2_dir/\"classifier_9_pretrained/checkpoint-5256\")\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        gpt2_dir / \"classifier_100_pretrained/checkpoint-13128\"\n",
    "    )\n",
    "    config.num_labels = len(label2id)\n",
    "    config.pad_token_id = tokenizer.pad_token_id\n",
    "    # model = AutoModelForSequenceClassification.from_pretrained(gpt2_dir/\"classifier_9_pretrained/checkpoint-5256\", config=config)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        gpt2_dir / \"classifier_100_pretrained/checkpoint-13128\", config=config\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "    )\n",
    "\n",
    "    num_training_steps = (\n",
    "        len(train_ds)\n",
    "        // training_args.per_device_train_batch_size\n",
    "        * training_args.num_train_epochs\n",
    "    )\n",
    "    scheduler = get_scheduler(\n",
    "        \"cosine\",\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,  # You can adjust the warmup steps if needed\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        # output_dir=gpt2_dir/f\"LPFT_9_{lr}\",\n",
    "        output_dir=gpt2_dir / f\"LPFT_100_{lr}\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        logging_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer, scheduler),\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate(test_ds)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omniglot??????\n",
    "# Good fewshot alphabet model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

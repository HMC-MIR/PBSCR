{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Training Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Currently only tested for GPT2!* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import time\n",
    "# import evaluate\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.normalizers import (Sequence, Lowercase, NFD, StripAccents)\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "from transformers import AutoConfig, \\\n",
    "    DataCollatorWithPadding, AutoModelForSequenceClassification, \\\n",
    "    Trainer, TrainingArguments, AutoTokenizer, GPT2Config\n",
    "from matplotlib import pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Path to save cache'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"/home/ajain/ttmp/PBSCSR_data/\")\n",
    "'''Path to large data folder'''\n",
    "\n",
    "gpt2_dir = data_path/\"gpt2\"\n",
    "\n",
    "seed = 42\n",
    "'''Random seed: int'''\n",
    "\n",
    "train_file = gpt2_dir/\"LM_pretraining_data/train.txt\"\n",
    "train_file.parent.mkdir(exist_ok=True)\n",
    "valid_file = gpt2_dir/\"LM_pretraining_data/valid.txt\"\n",
    "\n",
    "cache_dir = data_path/\".cache\"\n",
    "cache_dir.mkdir(exist_ok=True)\n",
    "'''Path to save cache'''\n",
    "\n",
    "# labeled_data_path = \"../../100_way_dataset.zip\"  # TODO: FILL IN AFTER UNZIPPING\n",
    "# '''Path to labeled data'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Full Finetuning Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the cell below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prewritten Helper Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_x_acc(y_true, y_pred, x):\n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "    ranked = torch.argsort(y_pred, axis=-1)\n",
    "    top_x = ranked[..., -x:]\n",
    "    return (top_x == torch.repeat_interleave(y_true.unsqueeze(-1), x, axis=-1)).float().sum(-1).mean().item()\n",
    "\n",
    "def mean_recip_rank(y_true, y_pred):\n",
    "    y_true = torch.tensor(y_true)\n",
    "    y_pred = torch.tensor(y_pred)\n",
    "    ranked = torch.argsort(y_pred, axis=-1)\n",
    "    true_ranks = y_pred.shape[-1] - (ranked == torch.repeat_interleave(y_true.unsqueeze(-1), y_pred.shape[-1], axis=-1)).float().argmax(-1)\n",
    "\n",
    "    return (1/true_ranks).mean().item()\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    top_one = top_x_acc(labels, predictions, 1)\n",
    "    top_five = top_x_acc(labels, predictions, 5)\n",
    "    top_ten = 0\n",
    "    if predictions.shape[-1] >= 10:\n",
    "        top_ten = top_x_acc(labels, predictions, 10)\n",
    "    mrr = mean_recip_rank(labels, predictions)\n",
    "\n",
    "    metrics = {\"top_one\" : top_one, \"top_five\" : top_five, \"mrr\": mrr, \"top_ten\": top_ten}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ajain/ttmp/PBSCSR_data/gpt2\n"
     ]
    }
   ],
   "source": [
    "print(gpt2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_filler(filler_file, imslp_bootleg_path, filler_threshold=0.5):\n",
    "    composer_dict = {}\n",
    "    with open(filler_file, \"r\") as fin:\n",
    "        lines = fin.readlines()\n",
    "        lines = [line.split(\"\\t\") for line in lines]\n",
    "        for path, page, score in lines:\n",
    "            parts = path.split(\"/\")\n",
    "            composer, piece, id = parts[0], \"/\".join(parts[1:-1]), parts[-1]\n",
    "            composer_dict[composer] = {} if composer not in composer_dict else composer_dict[composer]\n",
    "            composer_dict[composer][piece] = {} if piece not in composer_dict[composer] else composer_dict[composer][piece]\n",
    "            composer_dict[composer][piece][id] = {\"valid_pages\":[], \"count\":0, \"bscore\": []} if id not in composer_dict[composer][piece] else composer_dict[composer][piece][id]\n",
    "            if float(score) < filler_threshold:\n",
    "                bscore_page = pd.read_pickle(imslp_bootleg_path/f\"{path}.pkl\")[int(page)]\n",
    "                composer_dict[composer][piece][id][\"valid_pages\"].append(int(page))\n",
    "                composer_dict[composer][piece][id][\"count\"] += len(bscore_page)\n",
    "                composer_dict[composer][piece][id][\"bscore\"].append(bscore_page)\n",
    "    return composer_dict\n",
    "\n",
    "\n",
    "def ints_to_binary_matrix(score_seq):  # converts integer sequence to n x 62 matrix\n",
    "    matrix = []\n",
    "    for event in score_seq:\n",
    "        binary_rep = list(np.binary_repr(event, 62))\n",
    "        matrix.append(binary_rep)\n",
    "    np_mat = np.array(matrix, dtype=np.uint8)\n",
    "    #np_mat = np.flip(np_mat, axis=0)  # flip to have least significant bit at the front\n",
    "    return np_mat\n",
    "\n",
    "\n",
    "def create_dataset(pieces, valid_split=.15, test_split=.15):\n",
    "    \"\"\"\n",
    "    Creates a train / valid / test split dataset of pieces.\n",
    "    pieces: The list of binary_matrices to sample from\n",
    "    valid_split: The proportion of data to use for valid\n",
    "    test_split: The proportion of data to use for valid\n",
    "    \n",
    "    returns:\n",
    "    x & y lists for train, valid, and test sets\n",
    "    \"\"\"\n",
    "    \n",
    "    # For repeatability\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # shuffle pieces\n",
    "    piece_list = [piece for piece in pieces]\n",
    "    np.random.shuffle(piece_list)\n",
    "    \n",
    "    # Calculate starting places of each section - order is (test, valid, train)\n",
    "    train_start = round((valid_split+test_split)*len(piece_list))\n",
    "    valid_start = round(test_split*len(piece_list))\n",
    "    \n",
    "    # Go through and separate pieces into train, valid, test\n",
    "    train_pieces = piece_list[train_start:]\n",
    "    valid_pieces = piece_list[valid_start:train_start]\n",
    "    test_pieces = piece_list[:valid_start]\n",
    "    \n",
    "    return train_pieces, valid_pieces, test_pieces\n",
    "\n",
    "def merge_staff_overlaps(bscores):\n",
    "    \"\"\"\n",
    "    Takes in either one binary score or a batch of them and merges the left and right hands\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lower middle c is index 23\n",
    "    # Upper middle c is index 33\n",
    "    lower = 23\n",
    "    upper = 33\n",
    "    middle = (lower + upper) // 2\n",
    "    \n",
    "    # Total notes is 52\n",
    "    total = 52\n",
    "    \n",
    "    # Pad out upper hand and lower hand and combine them\n",
    "    padded_lower = np.concatenate([bscores[..., :middle], np.zeros((*bscores.shape[:-1], total-middle))], axis=-1)\n",
    "    padded_upper = np.concatenate([np.zeros((*bscores.shape[:-1], middle-bscores.shape[-1]+total)), bscores[..., middle:]], axis=-1)\n",
    "    # Logical or\n",
    "    merged = padded_lower + padded_upper - padded_lower * padded_upper\n",
    "    return merged\n",
    "\n",
    "\n",
    "# Dense Encoder\n",
    "\n",
    "# Continuous line of 256 unicode characters\n",
    "start = 10060# 931\n",
    "dense_characters = [chr(i).encode(\"utf-8\").decode(\"utf-8\") for i in range(start, start+512)]\n",
    "\n",
    "\n",
    "# This code divides the fragment into blocks (and discards any remaining info at the very edges)\n",
    "# Then it uses einsum with a filter of powers of 2 to convert from binary to an integer.  Then converts integers into\n",
    "# unicode characters\n",
    "\n",
    "def dense_encoder(fragment, block_size=[1, 1]):\n",
    "    fragment = merge_staff_overlaps(fragment)\n",
    "    # Rewrote this to be much faster but looks complicated\n",
    "    # This filter has powers of 2 which is how the binary is turned to ints\n",
    "    filter_ = np.power(2, np.arange(np.prod(block_size))).reshape(block_size)\n",
    "    \n",
    "    # The fragment is split into blocks here\n",
    "    xblocks = np.stack(np.split(fragment[:, :(fragment.shape[1]//block_size[1])*block_size[1]], fragment.shape[1]//block_size[1], axis=1))\n",
    "    xyblocks = np.stack(np.split(xblocks[:, :(xblocks.shape[1]//block_size[0])*block_size[0]], xblocks.shape[1]//block_size[0], axis=1))\n",
    "    \n",
    "    # The blocks are multiplied so they are ints\n",
    "    numbers = np.einsum(\"ijkl,kl->ij\", xyblocks, filter_)\n",
    "    \n",
    "    # The ints are turned into corresponding characters\n",
    "    characters = (numbers+start).astype(np.int32).view('U1')\n",
    "    return \" \".join([\"\".join(t) for t in characters])\n",
    "\n",
    "def data_preparation(labeled_data):\n",
    "    train_X, train_y, val_X, val_y, test_X, test_y, train_m, valid_m, test_m = pd.read_pickle(labeled_data)\n",
    "\n",
    "    train_df = pd.DataFrame({\"text\": [dense_encoder(piece, block_size=[1,8]) for piece in train_X], \"label\": train_y})\n",
    "    val_df = pd.DataFrame({\"text\": [dense_encoder(piece, block_size=[1,8]) for piece in val_X], \"label\": val_y})\n",
    "    test_df = pd.DataFrame({\"text\": [dense_encoder(piece, block_size=[1,8]) for piece in test_X], \"label\": test_y})\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def label2id_function(examples, label2id):\n",
    "    return {\"label\": [label2id[label] for label in examples[\"label\"]]}\n",
    "\n",
    "def tokenizer_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30_000\n",
    "\n",
    "pretrained_output = \"../../../PBSCSR_data/gpt2/classifier_100_pretrained/checkpoint-13128\"\n",
    "\n",
    "load_pretrained_weights = True\n",
    "\n",
    "config_class = GPT2Config\n",
    "'''Config class for language model: e.g. GPT2Config'''\n",
    "\n",
    "lm_config = {\n",
    "    'model_type': 'gpt2', # e.g. 'gpt2',\n",
    "    'vocab_size': vocab_size, # e.g. 50257,\n",
    "    'n_positions': 1024, # e.g. 1024,\n",
    "    'n_layer': 6, # e.g. 12,\n",
    "    # add more config here if needed\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1c5b523bf349ce9209944dbed99c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b805018679641fa9c0f9710c9dcd2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c221e5f19459bacd07b9062777b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec1780a71a0406ab25a1914cea387ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be64fa93a878400d9b77e8c24114a76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145c08f2b06549df908deee16b92804a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/abunn/ttmp/miniconda3/envs/EWLLMs/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13125' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13125/13125 1:28:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Top One</th>\n",
       "      <th>Top Five</th>\n",
       "      <th>Mrr</th>\n",
       "      <th>Top Ten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.521100</td>\n",
       "      <td>4.083024</td>\n",
       "      <td>0.126933</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.232362</td>\n",
       "      <td>0.451867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.934300</td>\n",
       "      <td>4.523793</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.231612</td>\n",
       "      <td>0.450467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.956100</td>\n",
       "      <td>4.927619</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.309867</td>\n",
       "      <td>0.228732</td>\n",
       "      <td>0.442667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abunn/ttmp/miniconda3/envs/EWLLMs/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/abunn/ttmp/miniconda3/envs/EWLLMs/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/abunn/ttmp/miniconda3/envs/EWLLMs/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='938' max='938' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [938/938 02:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.1455230712890625,\n",
       " 'eval_top_one': 0.12280000001192093,\n",
       " 'eval_top_five': 0.30506667494773865,\n",
       " 'eval_mrr': 0.22643429040908813,\n",
       " 'eval_top_ten': 0.437666654586792,\n",
       " 'eval_runtime': 164.7328,\n",
       " 'eval_samples_per_second': 91.057,\n",
       " 'eval_steps_per_second': 5.694,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "'''Batch size for classifier training: int'''\n",
    "epochs = 3\n",
    "'''Epochs for classifier training: int'''\n",
    "learning_rate = 5e-5\n",
    "'''Learning rate for classifier training: float e.g. 5e-5'''\n",
    "classifier_output_model_path = \"../../../PBSCSR_data/gpt2/100_way_LP_FT\"\n",
    "\n",
    "# Prepare data\n",
    "# !unzip -o {labeled_data_path} -d {data_path} \n",
    "labeled_data = data_path/\"100_way_dataset.pkl\"\n",
    "train_df, val_df, test_df = data_preparation(labeled_data)\n",
    "\n",
    "train_ds = Dataset.from_dict(train_df)\n",
    "val_ds = Dataset.from_dict(val_df)\n",
    "test_ds = Dataset.from_dict(test_df)\n",
    "\n",
    "# Define label map\n",
    "label2id = {label: i for i, label in enumerate(set(train_df['label']))}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_output)# , return_token_type_ids=False)\n",
    "tokenizer.pad_token = '<pad>'\n",
    "\n",
    "def tokenizer_function(examples, tokenizer):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
    "\n",
    "# Define model\n",
    "if load_pretrained_weights:\n",
    "    config = AutoConfig.from_pretrained(pretrained_output)\n",
    "    config.num_labels = len(label2id)\n",
    "    config.pad_token_id = tokenizer.pad_token_id\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_output, config=config).to(\"cuda\")\n",
    "else:\n",
    "    config = config_class(**lm_config)\n",
    "    config.num_labels = len(label2id)\n",
    "    config.pad_token_id = tokenizer.pad_token_id\n",
    "    model = AutoModelForSequenceClassification.from_config(config).to(\"cuda\")\n",
    "tokenizer.model_max_length = config.n_positions\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Tokenize and convert labels to ids\n",
    "train_ds = train_ds.map(tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "val_ds = val_ds.map(tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "test_ds = test_ds.map(tokenizer_function, batched=True, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "train_ds = train_ds.map(label2id_function, batched=True, fn_kwargs={\"label2id\": label2id})\n",
    "val_ds = val_ds.map(label2id_function, batched=True, fn_kwargs={\"label2id\": label2id})\n",
    "test_ds = test_ds.map(label2id_function, batched=True, fn_kwargs={\"label2id\": label2id})\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\", max_length=1024)\n",
    "\n",
    "# Freeze all layers except the classifier\n",
    "# NOT FREEZING ANYMORE\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     param.requires_grad = False\n",
    "# model.score.weight.requires_grad = True\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=classifier_output_model_path,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "trainer.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Language Model Classifier Finetuning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize training and validation losses\n",
    "with open(\"/home/abunn/ttmp/ExplorationWithLLMs/source/03_alec_temp_name/finetuned_models/dense_1_8/log_history.json\", \"r\") as fin:\n",
    "    log_history = json.load(fin)\n",
    "\n",
    "step, tr_loss, val_loss = [], [], []\n",
    "acc = []\n",
    "for epoch in log_history:\n",
    "    step.append(epoch[\"epoch\"])\n",
    "    tr_loss.append(epoch[\"train_loss\"])\n",
    "    val_loss.append(epoch[\"val_loss\"])\n",
    "    acc.append(epoch[\"accuracy\"])\n",
    "\n",
    "step, tr_loss, val_loss = np.array(step), np.array(tr_loss), np.array(val_loss)\n",
    "plt.plot(step, tr_loss, 'k-', label=\"Train\")\n",
    "plt.scatter(step, tr_loss, c='k')\n",
    "plt.plot(step, val_loss, 'g-', label=\"Validation\")\n",
    "plt.scatter(step, val_loss, c='g')\n",
    "plt.legend()\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(step, acc, 'g-', label=\"Validation\")\n",
    "plt.scatter(step, acc, c='g')\n",
    "plt.legend()\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
